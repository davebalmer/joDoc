#!/usr/bin/env perl
# Everything moved into one file, does things the right way
use strict;
use warnings;
use Getopt::Long;
use IPC::Open2;

# parse the input options
my $markdown_bin;
my $outputdir;
my $title;
my $toc;
my $template;
my %h1s          = ();
my %processed    = ();
my %files_to_h1s = ();

GetOptions(
    "markdown=s" => \$markdown_bin,
    "output=s"   => \$outputdir,
    "title=s"    => \$title,
    "toc=s"      => \$toc,
    "title=s"    => \$title,
    "template=s" => \$template
) or die;

die
"You need to specify a template file for a table of contents, and have specified --output.\n"
  if ( $toc && !defined($outputdir) );

$title = "joDoc" unless ( defined($title) );

# grab comments out of incoming text
sub docker {
    my $input  = shift;
    my @output = ();
    my $line;
    while ( $input =~ m{\/\*\*(?:.|[\r\n])*?\*/}g ) {
        $line = $&;
        $line =~ s{(\*\/|\/\*\*)}{}g;
        $line =~ s{([\r\n]+)\s{1}}{$1}g;
        push( @output, "\r$line\r" );
    }
    return join( "", @output );
}

# put a nice header on the html output
sub html_head {
    my $input = shift;

    # TODO: needs to support header/footer HTML templates at a minimum.
    # we could use a formal templating system, but for initial release
    # let's keep it simple
    my $output = qq(
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>$title</title>
<meta name="generator" content="joDoc">
<link rel="stylesheet" type="text/css" href="docbody.css">
<link rel="stylesheet" type="text/css" href="doc.css">
<meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0, user-scalable=no, width=device-width">
<meta name="format-detection" content="false">
</head>
<body>

$input

</body>
</html>);
    return $output;
}

# Read file into a string
sub read_file {
    my $in = shift;
    my $out;
    open( my $fh, '<', $in ) or die $!;
    {

        # Deactivate input record separator
        local $/;
        $out = <$fh>;
    }
    close $fh or die $!;
    return $out;
}

# link together all the html output, make an index at the bottom of each page
# will link between all files in the output
sub autolink {
    for my $file ( keys %processed ) {
        my $input = $processed{$file};

        # put an external css class on outbound links
        $input =~
          s{(\<a)\s+(href=\"(?:http|mailto|ftp))}{$1 class=\"external\" $2}g;
        my @keywords = keys %h1s;
        if (@keywords) {

            # prepare for the regex
            my $keys = join( "|", @keywords );

            # make anything refing a keywork link to it
            if ($outputdir) {
                $input =~
s/(\W+)($keys)(?!\<\/a|\w+)/$1\<a href=\"$h1s{$2}\#$2\"\>$2\<\/a\>/g;

                # make a #tag for the keyword h1 tag
                $input =~ s/\<h1\>\<a href=\"[^\#\>]*\#/\<h1\>\<a name=\"/g;
            }
            else {

                $input =~
                  s/(\W+)($keys)(?!\<\/a|\w+)/$1\<a href=\"\#$2\"\>$2\<\/a\>/g;

                # make a #tag for the keyword h1 tag
                $input =~ s/\<h1\>\<a href=\"\#/\<h1\>\<a name=\"/g;
            }
        }

        $processed{$file} = $input;
    }
}

# Make an alphasorted index
sub indexer {
    my @keywords   = keys %h1s;
    my $index      = qq(\n\n<hr>\n\n<h1>Index</h1>\n<div id="index">\n);
    my $lastletter = "ZZ";

    for my $i ( sort { lc($a) cmp lc($b) } @keywords ) {
        my $letter = uc( substr( $i, 0, 1 ) );
        if ( $letter ne $lastletter ) {
            if ( $lastletter ne "ZZ" ) {
                $index .= "</ul>\n";
            }
            $index .= "\n<h2>$letter</h2>\n";
            $index .= "\n<ul>\n";
            $lastletter = $letter;
        }
        if ($outputdir) {
            $index .= qq(<li><a href="$h1s{$i}#$i">$i</a></li>\n);
        }
        else {
            $index .= qq(<li><a href="#$i">$i</a></li>\n);
        }

    }
    $index .= "</ul></div>\n\n";
    return $index;
}

# Pipe stuff through markdown for parsing
sub markdown_pipe {
    my $in  = shift;
    my @out = ();

    # Use pipes instead of temp files
    # The magic here is what you expect open(HANDLE, "| $markdown_bin |") to do.
    my $pid = open2( my $chld_out, my $chld_in, $markdown_bin ) or die $!;
    print $chld_in $in;
    close $chld_in or die $!;
    while (<$chld_out>) {
        push( @out, $_ );
    }
    close $chld_out or die $!;
    return join( "", @out );
}

# Find all the h1tags for all files
sub h1finder {
    %h1s          = ();
    %files_to_h1s = ();
    for my $file ( keys %processed ) {
        my @h1      = ();
        my $content = $processed{$file};
        while ( $content =~ m{\<h1\>([^\<]+)\<\/h1\>}g ) {
            push( @h1, $1 );
        }
        $h1s{$_} = $file for @h1;
        $files_to_h1s{$file} = \@h1;
    }
}

sub toclinker {
    my $indent         = shift;
    my $pathpart       = shift;
    my @matching_files = keys %files_to_h1s;
    @matching_files = grep { m{$pathpart} } @matching_files;
    my @matching_h1s = ();
    push( @matching_h1s, @{ $files_to_h1s{$_} } ) for @matching_files;
    @matching_h1s = sort { lc($a) cmp lc($b) } @matching_h1s;
    $_ = $indent . '* ' . $_ . "\n" for @matching_h1s;
    return join( "", @matching_h1s );
}

# munge output file names
sub munge {
    my %munged_processed = ();
    for my $file ( keys %processed ) {
        my @path_parts = split( /\//, $file );
        s{\.+}{_}g for @path_parts;
        my $path = join( '_', @path_parts );
        my $munged = $path . '.html';
        $munged_processed{$munged} = $processed{$file};
    }
    %processed = %munged_processed;
}

sub main {

    # If not specified, find a markdown parser in the path
    chomp( $markdown_bin = qx(which markdown) ) unless $markdown_bin;

    # We can't do anything if we can't call markdown
    die "Markdown parser not found!\n" unless ( -x $markdown_bin );

    # Slurp all the files and process them
    # recurse current directory if no input arguments
    my @files = @ARGV;
    @files = glob("./*") unless ( $ARGV[0] );
    for my $file (@files) {
        unless ( -e $file ) {
            warn "$file not found!\n";
            next;
        }

        # recurse
        if ( -d $file ) {
            my @subdir = glob("$file/*");
            push( @files, @subdir );
            next;
        }

        if ( $file =~ m{\.(js|css|mdown|html|md|markdown|htm)$}i ) {
            my $content = read_file($file);

            # javascript and css files get "cleaned"
            if ( $file =~ m{\.(js|css)$} ) {
                $content = docker($content);
            }

            # pure htmlfiles don't have markdown applied
            unless ( $file =~ m{\.html$} ) {
                $content = markdown_pipe($content);
            }
            $processed{$file} = $content;
        }
    }

    #TODO: This is a nasty hack, but it works. Fix when times are better.
    if ($toc) {
        h1finder;
        my @toclinked;
        open( my $fh, '<', $toc ) or die $!;
        my @content = <$fh>;
        close $fh or die $!;
        for my $line (@content) {
            if ( $line =~ m/(\s*).\s*{(.+)}/ ) {
                $line = toclinker( $1, $2 );
            }
            push( @toclinked, $line );
        }
        $processed{_content} = markdown_pipe( join( "", @toclinked ) );
    }
    munge;
    h1finder;
    autolink;

    # Print docs to separate files in the same hierarchy as the input
    if ($outputdir) {
        $processed{"_index.html"} = indexer;
        mkdir $outputdir;
        for my $file ( keys %processed ) {
            open( my $fh, '>', $outputdir . '/' . $file ) or die $!;
            print $fh html_head( $processed{$file} );
            close $fh or die;
        }
    }

    # Print to stdout
    else {
        print html_head( join( "", values %processed ) . indexer );
    }
}

main;
